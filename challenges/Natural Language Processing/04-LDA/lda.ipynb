{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ The goal of this challenge is to find topics within a corpus of emails with the **LDA** algorithm (Unsupervised Learning in NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úâÔ∏è Here is a collection of 1K+ ***unlabelled emails***. Let's try to ***extract topics*** from them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...\n",
       "1  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "2  From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...\n",
       "3  From: atterlep@vela.acs.oakland.edu (Cardinal ...\n",
       "4  From: vzhivov@superior.carleton.ca (Vladimir Z..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data', sep=\",\", header=None)\n",
    "data.columns = ['text']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1199, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Cleaning**) ‚ùì You're used to it by now... Clean up! Store the cleaned text in a new column \"clean_text\" of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') \n",
    "    tokenized = word_tokenize(sentence) # Tokenize\n",
    "    words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "    stop_words = set(stopwords.words('english')) # Make stopword list\n",
    "    without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words\n",
    "    lemma=WordNetLemmatizer() # Initiate Lemmatizer\n",
    "    lemmatized = [lemma.lemmatize(word) for word in without_stopwords] # Lemmatize\n",
    "    return lemmatized\n",
    "    # $CHALLENGIFY_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data['text'].apply(lambda x: preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data['clean_text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text          object\n",
       "clean_text    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Training)** ‚ùì Train a LDA model to extract potential topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg</th>\n",
       "      <th>aacc</th>\n",
       "      <th>aadams</th>\n",
       "      <th>aafreenetcarletonca</th>\n",
       "      <th>aargh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronbinahccbrandeisedu</th>\n",
       "      <th>aaroncathenamitedu</th>\n",
       "      <th>aassists</th>\n",
       "      <th>...</th>\n",
       "      <th>zombo</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zorasterism</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zupancic</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwart</th>\n",
       "      <th>zzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows √ó 19389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  \\\n",
       "0     0.0   \n",
       "1     0.0   \n",
       "2     0.0   \n",
       "3     0.0   \n",
       "4     0.0   \n",
       "...   ...   \n",
       "1194  0.0   \n",
       "1195  0.0   \n",
       "1196  0.0   \n",
       "1197  0.0   \n",
       "1198  0.0   \n",
       "\n",
       "      aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg  \\\n",
       "0                                                   0.0                                 \n",
       "1                                                   0.0                                 \n",
       "2                                                   0.0                                 \n",
       "3                                                   0.0                                 \n",
       "4                                                   0.0                                 \n",
       "...                                                 ...                                 \n",
       "1194                                                0.0                                 \n",
       "1195                                                0.0                                 \n",
       "1196                                                0.0                                 \n",
       "1197                                                0.0                                 \n",
       "1198                                                0.0                                 \n",
       "\n",
       "      aacc  aadams  aafreenetcarletonca  aargh  aaron  \\\n",
       "0      0.0     0.0             0.000000    0.0    0.0   \n",
       "1      0.0     0.0             0.086861    0.0    0.0   \n",
       "2      0.0     0.0             0.000000    0.0    0.0   \n",
       "3      0.0     0.0             0.000000    0.0    0.0   \n",
       "4      0.0     0.0             0.000000    0.0    0.0   \n",
       "...    ...     ...                  ...    ...    ...   \n",
       "1194   0.0     0.0             0.000000    0.0    0.0   \n",
       "1195   0.0     0.0             0.000000    0.0    0.0   \n",
       "1196   0.0     0.0             0.000000    0.0    0.0   \n",
       "1197   0.0     0.0             0.000000    0.0    0.0   \n",
       "1198   0.0     0.0             0.000000    0.0    0.0   \n",
       "\n",
       "      aaronbinahccbrandeisedu  aaroncathenamitedu  aassists  ...  zombo  \\\n",
       "0                         0.0                 0.0       0.0  ...    0.0   \n",
       "1                         0.0                 0.0       0.0  ...    0.0   \n",
       "2                         0.0                 0.0       0.0  ...    0.0   \n",
       "3                         0.0                 0.0       0.0  ...    0.0   \n",
       "4                         0.0                 0.0       0.0  ...    0.0   \n",
       "...                       ...                 ...       ...  ...    ...   \n",
       "1194                      0.0                 0.0       0.0  ...    0.0   \n",
       "1195                      0.0                 0.0       0.0  ...    0.0   \n",
       "1196                      0.0                 0.0       0.0  ...    0.0   \n",
       "1197                      0.0                 0.0       0.0  ...    0.0   \n",
       "1198                      0.0                 0.0       0.0  ...    0.0   \n",
       "\n",
       "          zone  zoo  zoomed  zorasterism  zubov  zupancic  zurich  zwart  \\\n",
       "0     0.000000  0.0     0.0          0.0    0.0       0.0     0.0    0.0   \n",
       "1     0.000000  0.0     0.0          0.0    0.0       0.0     0.0    0.0   \n",
       "2     0.000000  0.0     0.0          0.0    0.0       0.0     0.0    0.0   \n",
       "3     0.000000  0.0     0.0          0.0    0.0       0.0     0.0    0.0   \n",
       "4     0.071741  0.0     0.0          0.0    0.0       0.0     0.0    0.0   \n",
       "...        ...  ...     ...          ...    ...       ...     ...    ...   \n",
       "1194  0.000000  0.0     0.0          0.0    0.0       0.0     0.0    0.0   \n",
       "1195  0.000000  0.0     0.0          0.0    0.0       0.0     0.0    0.0   \n",
       "1196  0.000000  0.0     0.0          0.0    0.0       0.0     0.0    0.0   \n",
       "1197  0.000000  0.0     0.0          0.0    0.0       0.0     0.0    0.0   \n",
       "1198  0.000000  0.0     0.0          0.0    0.0       0.0     0.0    0.0   \n",
       "\n",
       "      zzzzzz  \n",
       "0        0.0  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  \n",
       "...      ...  \n",
       "1194     0.0  \n",
       "1195     0.0  \n",
       "1196     0.0  \n",
       "1197     0.0  \n",
       "1198     0.0  \n",
       "\n",
       "[1199 rows x 19389 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorized_documents = vectorizer.fit_transform(data['clean_text'])\n",
    "vectorized_documents = pd.DataFrame(vectorized_documents.toarray(), \n",
    "                                    columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "vectorized_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(max_iter=100, n_components=5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Instantiate the LDA \n",
    "n_components = 5\n",
    "lda_model = LatentDirichletAllocation(n_components=n_components, max_iter = 100)\n",
    "\n",
    "# Fit the LDA on the vectorized documents\n",
    "lda_model.fit(vectorized_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word_mixture = pd.DataFrame(lda_model.components_, \n",
    "                                 columns = vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg</th>\n",
       "      <th>aacc</th>\n",
       "      <th>aadams</th>\n",
       "      <th>aafreenetcarletonca</th>\n",
       "      <th>aargh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronbinahccbrandeisedu</th>\n",
       "      <th>aaroncathenamitedu</th>\n",
       "      <th>aassists</th>\n",
       "      <th>...</th>\n",
       "      <th>zombo</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zorasterism</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zupancic</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwart</th>\n",
       "      <th>zzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.592012</td>\n",
       "      <td>0.200975</td>\n",
       "      <td>0.234539</td>\n",
       "      <td>0.200283</td>\n",
       "      <td>1.898426</td>\n",
       "      <td>0.200005</td>\n",
       "      <td>1.488170</td>\n",
       "      <td>0.676765</td>\n",
       "      <td>0.569512</td>\n",
       "      <td>0.200009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200006</td>\n",
       "      <td>0.200007</td>\n",
       "      <td>0.200014</td>\n",
       "      <td>0.200008</td>\n",
       "      <td>0.282841</td>\n",
       "      <td>0.200005</td>\n",
       "      <td>0.200005</td>\n",
       "      <td>0.200009</td>\n",
       "      <td>0.538734</td>\n",
       "      <td>0.200011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200018</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.200016</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>0.200010</td>\n",
       "      <td>0.200011</td>\n",
       "      <td>0.200012</td>\n",
       "      <td>0.200020</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200012</td>\n",
       "      <td>0.200008</td>\n",
       "      <td>0.200030</td>\n",
       "      <td>0.200017</td>\n",
       "      <td>0.200017</td>\n",
       "      <td>0.200010</td>\n",
       "      <td>0.200009</td>\n",
       "      <td>0.200015</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.200023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.200018</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.200016</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>0.200010</td>\n",
       "      <td>0.200011</td>\n",
       "      <td>0.200012</td>\n",
       "      <td>0.200020</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200012</td>\n",
       "      <td>0.200008</td>\n",
       "      <td>0.200030</td>\n",
       "      <td>0.200017</td>\n",
       "      <td>0.200017</td>\n",
       "      <td>0.200010</td>\n",
       "      <td>0.200009</td>\n",
       "      <td>0.200015</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.200023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.208622</td>\n",
       "      <td>0.300013</td>\n",
       "      <td>0.200008</td>\n",
       "      <td>0.206197</td>\n",
       "      <td>0.207672</td>\n",
       "      <td>0.971785</td>\n",
       "      <td>0.200005</td>\n",
       "      <td>0.200006</td>\n",
       "      <td>0.200010</td>\n",
       "      <td>0.277751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466287</td>\n",
       "      <td>2.277234</td>\n",
       "      <td>0.363448</td>\n",
       "      <td>0.461411</td>\n",
       "      <td>0.200010</td>\n",
       "      <td>1.465741</td>\n",
       "      <td>0.287793</td>\n",
       "      <td>0.358939</td>\n",
       "      <td>0.200010</td>\n",
       "      <td>0.381856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200018</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.200016</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>0.200010</td>\n",
       "      <td>0.200011</td>\n",
       "      <td>0.200012</td>\n",
       "      <td>0.200020</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200012</td>\n",
       "      <td>0.200008</td>\n",
       "      <td>0.200030</td>\n",
       "      <td>0.200017</td>\n",
       "      <td>0.200017</td>\n",
       "      <td>0.200010</td>\n",
       "      <td>0.200009</td>\n",
       "      <td>0.200015</td>\n",
       "      <td>0.200022</td>\n",
       "      <td>0.200023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 19389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aa  \\\n",
       "0  0.592012   \n",
       "1  0.200018   \n",
       "2  0.200018   \n",
       "3  0.208622   \n",
       "4  0.200018   \n",
       "\n",
       "   aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg  \\\n",
       "0                                           0.200975                                 \n",
       "1                                           0.200022                                 \n",
       "2                                           0.200022                                 \n",
       "3                                           0.300013                                 \n",
       "4                                           0.200022                                 \n",
       "\n",
       "       aacc    aadams  aafreenetcarletonca     aargh     aaron  \\\n",
       "0  0.234539  0.200283             1.898426  0.200005  1.488170   \n",
       "1  0.200016  0.200002             0.200021  0.200010  0.200011   \n",
       "2  0.200016  0.200002             0.200021  0.200010  0.200011   \n",
       "3  0.200008  0.206197             0.207672  0.971785  0.200005   \n",
       "4  0.200016  0.200002             0.200021  0.200010  0.200011   \n",
       "\n",
       "   aaronbinahccbrandeisedu  aaroncathenamitedu  aassists  ...     zombo  \\\n",
       "0                 0.676765            0.569512  0.200009  ...  0.200006   \n",
       "1                 0.200012            0.200020  0.200021  ...  0.200012   \n",
       "2                 0.200012            0.200020  0.200021  ...  0.200012   \n",
       "3                 0.200006            0.200010  0.277751  ...  0.466287   \n",
       "4                 0.200012            0.200020  0.200021  ...  0.200012   \n",
       "\n",
       "       zone       zoo    zoomed  zorasterism     zubov  zupancic    zurich  \\\n",
       "0  0.200007  0.200014  0.200008     0.282841  0.200005  0.200005  0.200009   \n",
       "1  0.200008  0.200030  0.200017     0.200017  0.200010  0.200009  0.200015   \n",
       "2  0.200008  0.200030  0.200017     0.200017  0.200010  0.200009  0.200015   \n",
       "3  2.277234  0.363448  0.461411     0.200010  1.465741  0.287793  0.358939   \n",
       "4  0.200008  0.200030  0.200017     0.200017  0.200010  0.200009  0.200015   \n",
       "\n",
       "      zwart    zzzzzz  \n",
       "0  0.538734  0.200011  \n",
       "1  0.200022  0.200023  \n",
       "2  0.200022  0.200023  \n",
       "3  0.200010  0.381856  \n",
       "4  0.200022  0.200023  \n",
       "\n",
       "[5 rows x 19389 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_mixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (3) Visualize potential topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéÅ We coded for you a  function that prints the words associated with the potential topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names_out()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Print the topics extracted by your LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('god', 35.24028798498692), ('christian', 22.02696956087202), ('jesus', 18.69060618938084), ('people', 16.52165638461461), ('would', 16.245723070134886), ('church', 16.146022924001947), ('one', 15.77157398065796), ('bible', 13.400911715851686), ('believe', 12.773527512121278), ('say', 12.435351135708782)]\n",
      "Topic 1:\n",
      "[('klingon', 0.6371143985681904), ('barone', 0.5482628389160791), ('pbaronexaessharriscom', 0.5482628389160791), ('romford', 0.41148942821992784), ('swindon', 0.41148942821992784), ('humberside', 0.41148942821992784), ('basingstoke', 0.41148942821992784), ('slough', 0.41148942821992784), ('billingham', 0.41148942821992784), ('peterborough', 0.41148942821992784)]\n",
      "Topic 2:\n",
      "[('testing', 1.3857661006194322), ('rfl', 0.8871619923566103), ('khettryrwpubutkedu', 0.8871619923566103), ('tennessee', 0.8871619923566103), ('singapore', 0.88681682525264), ('sturm', 0.7970038377623305), ('gakwrscom', 0.6949200387424055), ('dee', 0.626781192271493), ('ladwig', 0.574521138884944), ('drbombaynetlinkctscom', 0.574521138884944)]\n",
      "Topic 3:\n",
      "[('game', 26.238894527318646), ('team', 25.165213587043464), ('hockey', 18.218137902672574), ('player', 17.870888200438483), ('go', 14.696977864304348), ('play', 14.029228098619289), ('nhl', 13.161651465035515), ('playoff', 12.795542675255279), ('year', 12.633347855629165), ('win', 12.279418457325844)]\n",
      "Topic 4:\n",
      "[('labri', 0.7732122512079849), ('sy', 0.6679633434767825), ('mvscecwustledu', 0.6679633434767825), ('barbara', 0.6352738817595427), ('gifford', 0.5455959798146952), ('giffordoasysdtnavymil', 0.5455959798146952), ('paradox', 0.5213846294931739), ('virata', 0.41576665841596966), ('exdevil', 0.41576665841596966), ('mentor', 0.37462139014785756)]\n"
     ]
    }
   ],
   "source": [
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Predict the document-topic mixture of a new text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Prediction)** ‚ùì\n",
    "\n",
    "Now that your LDA model is fitted, you can use it to predict the topics of a new text.\n",
    "\n",
    "1. Vectorize the example\n",
    "2. Use the LDA on the vectorized example to predict the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"My team performed poorly last season. Their best player was out injured and only played one game\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinru/Projects/le_wagon_lectures/lewagon/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LatentDirichletAllocation was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05053579, 0.04949582, 0.04949541, 0.80097707, 0.04949591]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.transform(vectorizer.transform(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "      <td>['gldcunixbcccolumbiaedu', 'gary', 'l', 'dare'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>['atterlepvelaacsoaklandedu', 'cardinal', 'xim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...</td>\n",
       "      <td>['minerkuhubccukansedu', 'subject', 'ancient',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: atterlep@vela.acs.oakland.edu (Cardinal ...</td>\n",
       "      <td>['atterlepvelaacsoaklandedu', 'cardinal', 'xim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: vzhivov@superior.carleton.ca (Vladimir Z...</td>\n",
       "      <td>['vzhivovsuperiorcarletonca', 'vladimir', 'zhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>From: jerryb@eskimo.com (Jerry Kaufman)\\nSubje...</td>\n",
       "      <td>['jerrybeskimocom', 'jerry', 'kaufman', 'subje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>From: golchowy@alchemy.chem.utoronto.ca (Geral...</td>\n",
       "      <td>['golchowyalchemychemutorontoca', 'gerald', 'o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>From: jayne@mmalt.guild.org (Jayne Kulikauskas...</td>\n",
       "      <td>['jaynemmaltguildorg', 'jayne', 'kulikauskas',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>From: sclark@epas.utoronto.ca (Susan Clark)\\nS...</td>\n",
       "      <td>['sclarkepasutorontoca', 'susan', 'clark', 'su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>From: lmvec@westminster.ac.uk (William Hargrea...</td>\n",
       "      <td>['lmvecwestminsteracuk', 'william', 'hargreave...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     From: gld@cunixb.cc.columbia.edu (Gary L Dare)...   \n",
       "1     From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "2     From: miner@kuhub.cc.ukans.edu\\nSubject: Re: A...   \n",
       "3     From: atterlep@vela.acs.oakland.edu (Cardinal ...   \n",
       "4     From: vzhivov@superior.carleton.ca (Vladimir Z...   \n",
       "...                                                 ...   \n",
       "1194  From: jerryb@eskimo.com (Jerry Kaufman)\\nSubje...   \n",
       "1195  From: golchowy@alchemy.chem.utoronto.ca (Geral...   \n",
       "1196  From: jayne@mmalt.guild.org (Jayne Kulikauskas...   \n",
       "1197  From: sclark@epas.utoronto.ca (Susan Clark)\\nS...   \n",
       "1198  From: lmvec@westminster.ac.uk (William Hargrea...   \n",
       "\n",
       "                                             clean_text  \n",
       "0     ['gldcunixbcccolumbiaedu', 'gary', 'l', 'dare'...  \n",
       "1     ['atterlepvelaacsoaklandedu', 'cardinal', 'xim...  \n",
       "2     ['minerkuhubccukansedu', 'subject', 'ancient',...  \n",
       "3     ['atterlepvelaacsoaklandedu', 'cardinal', 'xim...  \n",
       "4     ['vzhivovsuperiorcarletonca', 'vladimir', 'zhi...  \n",
       "...                                                 ...  \n",
       "1194  ['jerrybeskimocom', 'jerry', 'kaufman', 'subje...  \n",
       "1195  ['golchowyalchemychemutorontoca', 'gerald', 'o...  \n",
       "1196  ['jaynemmaltguildorg', 'jayne', 'kulikauskas',...  \n",
       "1197  ['sclarkepasutorontoca', 'susan', 'clark', 'su...  \n",
       "1198  ['lmvecwestminsteracuk', 'william', 'hargreave...  \n",
       "\n",
       "[1199 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! You know how to implement an LDA quickly.\n",
    "\n",
    "üíæ Don't forget to¬†`git add/commit/push`¬†your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
