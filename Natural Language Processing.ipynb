{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b325ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1461dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['   Bonjour, comment ca va ?     ',\n",
       " '    Heyyyyy, how are you doing ?   ',\n",
       " '        Hallo, wie gehts ?     ']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = ['   Bonjour, comment ca va ?     ',\n",
    "         '    Heyyyyy, how are you doing ?   ',\n",
    "         '        Hallo, wie gehts ?     ']\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca43540b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love koalas, koalas are the cutest animals on Earth.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I love koalas, koalas are the cutest animals on Earth.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79161287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linkin park ', ' metallica ', 'red hot chili peppers']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"linkin park / metallica /red hot chili peppers\"\n",
    "text.split(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd80807a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love football so much. football is my passion. who else loves football ?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i LOVE football sO mUch. FOOTBALL is my passion. Who else loves fOOtBaLL ?\"\n",
    "text\n",
    "text.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2820e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i do not recommend this restaurant, we waited for so long, like 30 minutes, this is ridiculous'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i do not recommend this restaurant, we waited for so long, like 30 minutes, this is ridiculous\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66bc77ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string # \"string\" module is already installed with Python\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18e006e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love bubble tea OMG so tasty channel XOXO   '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for punctuation in string.punctuation:\n",
    "    text = text.replace(punctuation, '') \n",
    "    \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1c7140e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love bubble tea! OMG so #tasty @channel XOXO @$ ^_^ '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I love bubble tea! OMG so #tasty @channel XOXO @$ ^_^ \"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0229858a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i do not recommend this restaurant, we waited for so long, like  minutes, this is ridiculous'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = ''.join(char for char in text if not char.isdigit())\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa2f731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bonjour, comment ca va ?',\n",
       " 'Heyyyyy, how are you doing ?',\n",
       " 'Hallo, wie gehts ?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[text.strip() for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa40c75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"abcd Who is abcd ? That's not a real name!!! abcd\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"abcd Who is abcd ? That's not a real name!!! abcd\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "504f5365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Who is abcd ? That's not a real name!!! \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.strip('bdac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cc7c9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love koalas, koalas are the cuttest animals on Earth.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I love koalas, koalas are the cuttest animals on Earth.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3a056f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love pandas, pandas are the cuttest animals on Earth.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.replace(\"koala\",\"panda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baf36289",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"alicia keys / bts /justin bieber\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28a75231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alicia keys ', ' bts ', 'justin bieber']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dd16513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i LOVE football sO mUch. FOOTBALL is my passion. Who else loves fOOtBaLL ?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i LOVE football sO mUch. FOOTBALL is my passion. Who else loves fOOtBaLL ?\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f0ebce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love football so much. football is my passion. who else loves football ?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abef9449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i do not recommend this restaurant, we waited for so long, like 30 minutes, this is ridiculous'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i do not recommend this restaurant, we waited for so long, like 30 minutes, this is ridiculous\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4117e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i do not recommend this restaurant, we waited for so long, like  minutes, this is ridiculous'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = ''.join(char for char in text if not char.isdigit())\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbc41eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love bubble tea! OMG so #tasty @channel XOXO @$ ^_^ '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I love bubble tea! OMG so #tasty @channel XOXO @$ ^_^ \"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7322212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string # \"string\" module is already installed with Python\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9d15cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love bubble tea OMG so tasty channel XOXO   '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for punctuation in string.punctuation:\n",
    "    text = text.replace(punctuation, '') \n",
    "    \n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31b545f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"It isn't during our darkest moments that we must focus to see the light\", \n",
    "             \"  Le Wagon is amazing, take care - 666\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a38c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cleaning(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "    \n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') \n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c1af806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it isnt during our darkest moments that we must focus to see the light',\n",
       " 'le wagon is amazing take care']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentences = [basic_cleaning(sentence) for sentence in sentences]\n",
    "cleaned_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2a22001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Le Wagon!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"<head><body>Hello Le Wagon!</body></head>\"\"\"\n",
    "cleaned_text = re.sub('<[^<]+?>','', text)\n",
    "\n",
    "print (cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8649017f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['darkvador@gmail.com', 'batman@outlook.com']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "txt = 'This is a random text, authored by darkvador@gmail.com and batman@outlook.com, WOW!'\n",
    "\n",
    "re.findall('[\\w.+-]+@[\\w-]+\\.[\\w.-]+', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cf0f654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It isn't during our darkest moments that we must focus to see the light\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"It isn't during our darkest moments that we must focus to see the light\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9549c5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is during our darkest moments that we must focus to see the light'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'It is during our darkest moments that we must focus to see the light'\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f013329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'isnt',\n",
       " 'during',\n",
       " 'our',\n",
       " 'darkest',\n",
       " 'moments',\n",
       " 'that',\n",
       " 'we',\n",
       " 'must',\n",
       " 'focus',\n",
       " 'to',\n",
       " 'see',\n",
       " 'the',\n",
       " 'light']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "cleaned_sentence = basic_cleaning(text)\n",
    "word_tokens = word_tokenize(cleaned_sentence)\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4226afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) # you can also choose other languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7604764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"i\", \"am\", \"not\", \"going\", \"to\", \"go\", \"to\", \"the\", \n",
    "        \"club\", \"and\", \"party\", \"all\", \"night\", \"long\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b48b8de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'not', 'to', 'to', 'the', 'and', 'all']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_removed = [w for w in tokens if w in stop_words] \n",
    "stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "05ea7dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['isnt', 'darkest', 'moments', 'must', 'focus', 'see', 'light']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_cleaned = [w for w in word_tokens if not w in stop_words] \n",
    "tokens_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5044ca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/jinru/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eccc6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "\n",
    "stop_words = set(stopwords.words('english')) # you can also choose other languages\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edcd4855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('chinese')) # you can also choose other languages\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2620e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"i\", \"am\", \"not\", \"going\", \"to\", \"go\", \"to\", \"the\", \"club\", \n",
    "          \"and\",\"party\", \"all\", \"night\", \"long\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9662e86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'is',\n",
       " \"n't\",\n",
       " 'during',\n",
       " 'our',\n",
       " 'darkest',\n",
       " 'moments',\n",
       " 'that',\n",
       " 'we',\n",
       " 'must',\n",
       " 'focus',\n",
       " 'to',\n",
       " 'see',\n",
       " 'the',\n",
       " 'light']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ae2e95f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'during', 'our', 'that', 'we', 'to', 'the']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_removed = [w for w in word_tokens if w in stop_words] \n",
    "stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96fe376c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['going', 'go', 'club', 'party', 'night', 'long']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_cleaned = [w for w in tokens if not w in stop_words] \n",
    "tokens_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29f2d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'He was RUNNING and EATING at the same time =[. He has a bad habit of swimming after playing 3 hours in the Sun =/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "709fa352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he was running and eating at the same time  he has a bad habit of swimming after playing  hours in the sun'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentence = basic_cleaning(sentence)\n",
    "cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6917c9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'was', 'running', 'and', 'eating', 'at', 'the', 'same', 'time', 'he', 'has', 'a', 'bad', 'habit', 'of', 'swimming', 'after', 'playing', 'hours', 'in', 'the', 'sun']\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentence = word_tokenize(cleaned_sentence)\n",
    "print(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0962392e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['running',\n",
       " 'eating',\n",
       " 'time',\n",
       " 'bad',\n",
       " 'habit',\n",
       " 'swimming',\n",
       " 'playing',\n",
       " 'hours',\n",
       " 'sun']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentence_no_stopword = [w for w in tokenized_sentence if not w in stop_words] \n",
    "tokenized_sentence_no_stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b858ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# Lemmatizing the verbs\n",
    "verb_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"v\")  # v --> verbs\n",
    "              for word in tokenized_sentence_no_stopword]\n",
    "\n",
    "# 2 - Lemmatizing the nouns\n",
    "noun_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"n\")  # n --> nouns\n",
    "              for word in verb_lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5decedd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['running',\n",
       " 'eating',\n",
       " 'time',\n",
       " 'bad',\n",
       " 'habit',\n",
       " 'swimming',\n",
       " 'playing',\n",
       " 'hours',\n",
       " 'sun']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentence_no_stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfdad9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run', 'eat', 'time', 'bad', 'habit', 'swim', 'play', 'hours', 'sun']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44a78a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_lemmatized = [                 \n",
    "    WordNetLemmatizer().lemmatize(word, pos = \"n\") # n --> nouns\n",
    "    for word in verb_lemmatized\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48f606ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run', 'eat', 'time', 'bad', 'habit', 'swim', 'play', 'hour', 'sun']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e60954e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_vs_lemmatized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moriginal_vs_lemmatized\u001b[49m\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39mhide(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_vs_lemmatized' is not defined"
     ]
    }
   ],
   "source": [
    "original_vs_lemmatized.style.hide(axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3e816de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_sentence_no_stopword' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d_/vncnltvn4gsc7gbvnvg8j3dc0000gn/T/ipykernel_59368/4123601618.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Lemmatizing the verbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m verb_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"v\")  # v --> verbs\n\u001b[0;32m----> 4\u001b[0;31m               for word in tokenized_sentence_no_stopword]\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 2 - Lemmatizing the nouns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenized_sentence_no_stopword' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# Lemmatizing the verbs\n",
    "verb_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"v\")  # v --> verbs\n",
    "              for word in tokenized_sentence_no_stopword]\n",
    "\n",
    "# 2 - Lemmatizing the nouns\n",
    "noun_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"n\")  # n --> nouns\n",
    "              for word in verb_lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57203bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run', 'eat', 'time', 'bad', 'habit', 'swim', 'play', 'hours', 'sun']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f4b9e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run', 'eat', 'time', 'bad', 'habit', 'swim', 'play', 'hour', 'sun']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "baee825e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['running',\n",
       " 'eating',\n",
       " 'time',\n",
       " 'bad',\n",
       " 'habit',\n",
       " 'swimming',\n",
       " 'playing',\n",
       " 'hours',\n",
       " 'sun']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentence_no_stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8f0cd17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>verb_lemmatized</th>\n",
       "      <th>noun_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>running</td>\n",
       "      <td>run</td>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eating</td>\n",
       "      <td>eat</td>\n",
       "      <td>eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>habit</td>\n",
       "      <td>habit</td>\n",
       "      <td>habit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>swimming</td>\n",
       "      <td>swim</td>\n",
       "      <td>swim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>playing</td>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hours</td>\n",
       "      <td>hours</td>\n",
       "      <td>hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sun</td>\n",
       "      <td>sun</td>\n",
       "      <td>sun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original verb_lemmatized noun_lemmatized\n",
       "0   running             run             run\n",
       "1    eating             eat             eat\n",
       "2      time            time            time\n",
       "3       bad             bad             bad\n",
       "4     habit           habit           habit\n",
       "5  swimming            swim            swim\n",
       "6   playing            play            play\n",
       "7     hours           hours            hour\n",
       "8       sun             sun             sun"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([tokenized_sentence_no_stopword, verb_lemmatized, noun_lemmatized]).T\n",
    "df = df.rename(columns = {0:'original', 1:'verb_lemmatized', 2: 'noun_lemmatized'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81cceec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36954af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['the young dog is running with the cat',\n",
    "         'running is good for your health',\n",
    "         'your cat is young',\n",
    "         'young young young young young cat cat cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0276d0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 1, 2, 1, 1, 0],\n",
       "       [0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       "       [3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X = count_vectorizer.fit_transform(texts)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84184992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cat', 'dog', 'for', 'good', 'health', 'is', 'running', 'the',\n",
       "       'with', 'young', 'your'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7d04640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>for</th>\n",
       "      <th>good</th>\n",
       "      <th>health</th>\n",
       "      <th>is</th>\n",
       "      <th>running</th>\n",
       "      <th>the</th>\n",
       "      <th>with</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the young dog is running with the cat</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running is good for your health</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your cat is young</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young young young young young cat cat cat</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cat  dog  for  good  health  is  \\\n",
       "the young dog is running with the cat        1    1    0     0       0   1   \n",
       "running is good for your health              0    0    1     1       1   1   \n",
       "your cat is young                            1    0    0     0       0   1   \n",
       "young young young young young cat cat cat    3    0    0     0       0   0   \n",
       "\n",
       "                                           running  the  with  young  your  \n",
       "the young dog is running with the cat            1    2     1      1     0  \n",
       "running is good for your health                  1    0     0      0     1  \n",
       "your cat is young                                0    0     0      1     1  \n",
       "young young young young young cat cat cat        0    0     0      5     0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vectorized_texts = pd.DataFrame(\n",
    "    X.toarray(), \n",
    "    columns = count_vectorizer.get_feature_names_out(),\n",
    "    index = texts\n",
    ")\n",
    "\n",
    "vectorized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e31e4483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog        1\n",
       "for        1\n",
       "good       1\n",
       "health     1\n",
       "with       1\n",
       "running    2\n",
       "the        2\n",
       "your       2\n",
       "is         3\n",
       "cat        5\n",
       "young      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_texts.sum(axis=0).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95175f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0ab3a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>for</th>\n",
       "      <th>good</th>\n",
       "      <th>health</th>\n",
       "      <th>is</th>\n",
       "      <th>running</th>\n",
       "      <th>the</th>\n",
       "      <th>with</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.227904</td>\n",
       "      <td>0.357056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227904</td>\n",
       "      <td>0.281507</td>\n",
       "      <td>0.714112</td>\n",
       "      <td>0.357056</td>\n",
       "      <td>0.227904</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.295980</td>\n",
       "      <td>0.365594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470063</td>\n",
       "      <td>0.580622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.514496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857493</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat       dog       for      good    health        is   running  \\\n",
       "0  0.227904  0.357056  0.000000  0.000000  0.000000  0.227904  0.281507   \n",
       "1  0.000000  0.000000  0.463709  0.463709  0.463709  0.295980  0.365594   \n",
       "2  0.470063  0.000000  0.000000  0.000000  0.000000  0.470063  0.000000   \n",
       "3  0.514496  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        the      with     young      your  \n",
       "0  0.714112  0.357056  0.227904  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.365594  \n",
       "2  0.000000  0.000000  0.470063  0.580622  \n",
       "3  0.000000  0.000000  0.857493  0.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating the TfidfVectorizer\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Training it on the texts\n",
    "weighted_words = pd.DataFrame(tf_idf_vectorizer.fit_transform(texts).toarray(),\n",
    "                 columns = tf_idf_vectorizer.get_feature_names_out())\n",
    "\n",
    "weighted_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e558369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog</th>\n",
       "      <th>for</th>\n",
       "      <th>good</th>\n",
       "      <th>health</th>\n",
       "      <th>running</th>\n",
       "      <th>the</th>\n",
       "      <th>with</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the young dog is running with the cat</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running is good for your health</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your cat is young</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young young young young young cat cat cat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           dog  for  good  health  running  \\\n",
       "the young dog is running with the cat        1    0     0       0        1   \n",
       "running is good for your health              0    1     1       1        1   \n",
       "your cat is young                            0    0     0       0        0   \n",
       "young young young young young cat cat cat    0    0     0       0        0   \n",
       "\n",
       "                                           the  with  your  \n",
       "the young dog is running with the cat        2     1     0  \n",
       "running is good for your health              0     0     1  \n",
       "your cat is young                            0     0     1  \n",
       "young young young young young cat cat cat    0     0     0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the CountVectorizer with max_df = 2\n",
    "count_vectorizer = CountVectorizer(max_df = 2) # removing \"cat\", \"is\", \"young\"\n",
    "\n",
    "# Train it\n",
    "X = count_vectorizer.fit_transform(texts)\n",
    "X = pd.DataFrame(\n",
    "    X.toarray(),\n",
    "    columns = count_vectorizer.get_feature_names_out(),\n",
    "    index = texts\n",
    ")\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d3e3c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>is</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the young dog is running with the cat</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running is good for your health</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your cat is young</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young young young young young cat cat cat</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cat  is  young\n",
       "the young dog is running with the cat        1   1      1\n",
       "running is good for your health              0   1      0\n",
       "your cat is young                            1   1      1\n",
       "young young young young young cat cat cat    3   0      5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer with the 3 most frequent words\n",
    "count_vectorizer = CountVectorizer(max_features = 3)\n",
    "\n",
    "X = count_vectorizer.fit_transform(texts)\n",
    "X = pd.DataFrame(\n",
    "    X.toarray(),\n",
    "     columns = count_vectorizer.get_feature_names_out(),\n",
    "     index = texts\n",
    ")\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f1e76ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog</th>\n",
       "      <th>for</th>\n",
       "      <th>good</th>\n",
       "      <th>health</th>\n",
       "      <th>running</th>\n",
       "      <th>the</th>\n",
       "      <th>with</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the young dog is running with the cat</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running is good for your health</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your cat is young</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young young young young young cat cat cat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           dog  for  good  health  running  \\\n",
       "the young dog is running with the cat        1    0     0       0        1   \n",
       "running is good for your health              0    1     1       1        1   \n",
       "your cat is young                            0    0     0       0        0   \n",
       "young young young young young cat cat cat    0    0     0       0        0   \n",
       "\n",
       "                                           the  with  your  \n",
       "the young dog is running with the cat        2     1     0  \n",
       "running is good for your health              0     0     1  \n",
       "your cat is young                            0     0     1  \n",
       "young young young young young cat cat cat    0     0     0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the CountVectorizer with max_df = 2\n",
    "count_vectorizer = CountVectorizer(max_df = 2) # removing \"cat\", \"is\", \"young\"\n",
    "\n",
    "# Train it\n",
    "X = count_vectorizer.fit_transform(texts)\n",
    "X = pd.DataFrame(\n",
    "    X.toarray(),\n",
    "    columns = count_vectorizer.get_feature_names_out(),\n",
    "    index = texts\n",
    ")\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5deefede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>is</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the young dog is running with the cat</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>running is good for your health</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your cat is young</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young young young young young cat cat cat</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cat  is  young\n",
       "the young dog is running with the cat        1   1      1\n",
       "running is good for your health              0   1      0\n",
       "your cat is young                            1   1      1\n",
       "young young young young young cat cat cat    3   0      5"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer with the 3 most frequent words\n",
    "count_vectorizer = CountVectorizer(max_features = 3)\n",
    "\n",
    "X = count_vectorizer.fit_transform(texts)\n",
    "X = pd.DataFrame(\n",
    "    X.toarray(),\n",
    "     columns = count_vectorizer.get_feature_names_out(),\n",
    "     index = texts\n",
    ")\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29efafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_movie = [\"I like the movie but NOT the actors\",\n",
    "                \"I like the actors but NOT the movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d94c18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actors</th>\n",
       "      <th>but</th>\n",
       "      <th>like</th>\n",
       "      <th>movie</th>\n",
       "      <th>not</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I like the movie but NOT the actors</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like the actors but NOT the movie</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     actors  but  like  movie  not  the\n",
       "I like the movie but NOT the actors       1    1     1      1    1    2\n",
       "I like the actors but NOT the movie       1    1     1      1    1    2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the sentences\n",
    "count_vectorizer = CountVectorizer(stop_words=None)\n",
    "actors_movie_vectorized = count_vectorizer.fit_transform(actors_movie)\n",
    "\n",
    "# Show the representations in a nice DataFrame\n",
    "actors_movie_vectorized = pd.DataFrame(actors_movie_vectorized.toarray(),\n",
    "                                       columns = count_vectorizer.get_feature_names_out(),\n",
    "                                       index = actors_movie)\n",
    "\n",
    "# Show the vectorized movies\n",
    "actors_movie_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73708868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actors but</th>\n",
       "      <th>but not</th>\n",
       "      <th>like the</th>\n",
       "      <th>movie but</th>\n",
       "      <th>not the</th>\n",
       "      <th>the actors</th>\n",
       "      <th>the movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I like the movie but NOT the actors</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I like the actors but NOT the movie</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     actors but  but not  like the  movie but  \\\n",
       "I like the movie but NOT the actors           0        1         1          1   \n",
       "I like the actors but NOT the movie           1        1         1          0   \n",
       "\n",
       "                                     not the  the actors  the movie  \n",
       "I like the movie but NOT the actors        1           1          1  \n",
       "I like the actors but NOT the movie        1           1          1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the sentences\n",
    "count_vectorizer_n_gram = CountVectorizer(stop_words=None, ngram_range = (2,2))\n",
    "# count_vectorizer_n_gram = CountVectorizer(ngram_range = (2,2), token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\") # BI-GRAMS\n",
    "actors_movie_vectorized_n_gram = count_vectorizer_n_gram.fit_transform(actors_movie)\n",
    "\n",
    "# Show the representations in a nice DataFrame\n",
    "actors_movie_vectorized_n_gram = pd.DataFrame(actors_movie_vectorized_n_gram.toarray(),\n",
    "                                              columns = count_vectorizer_n_gram.get_feature_names_out(),\n",
    "                                              index = actors_movie)\n",
    "\n",
    "# Show the vectorized movies with bigrams\n",
    "actors_movie_vectorized_n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "310ccbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like the movie but NOT the actors', 'I like the actors but NOT the movie']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f07f3003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/bayes.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"images/bayes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6c7244a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/bayes2.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"images/bayes2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37abd6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"emails.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3910a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5728, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0ac9a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c0262d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.76\n",
       "1    0.24\n",
       "Name: spam, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(data[\"spam\"].value_counts(normalize = True),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5592e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "5723    0\n",
       "5724    0\n",
       "5725    0\n",
       "5726    0\n",
       "5727    0\n",
       "Name: spam, Length: 5728, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac9851b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Feature/Target\n",
    "X = data[\"text\"]\n",
    "y = data[\"spam\"]\n",
    "\n",
    "# Pipeline vectorizer + Naive Bayes\n",
    "pipeline_naive_bayes = make_pipeline(TfidfVectorizer(), \n",
    "                                     MultinomialNB())\n",
    "\n",
    "# Cross-validation\n",
    "cv_results = cross_validate(pipeline_naive_bayes, X, y, cv = 5, scoring = [\"recall\"])\n",
    "average_recall = cv_results[\"test_recall\"].mean()\n",
    "np.round(average_recall,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd0b9e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Score = 0.9524932488436137\n",
      "Best params = {'multinomialnb__alpha': 0.1, 'tfidfvectorizer__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of parameters\n",
    "parameters = {\n",
    "    'tfidfvectorizer__ngram_range': ((1,1), (2,2)),\n",
    "    'multinomialnb__alpha': (0.1,1)\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_naive_bayes,\n",
    "    parameters,\n",
    "    scoring = \"recall\",\n",
    "    cv = 5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(data.text,data.spam)\n",
    "\n",
    "# Best score\n",
    "print(f\"Best Score = {grid_search.best_score_}\")\n",
    "\n",
    "# Best params\n",
    "print(f\"Best params = {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "146aa1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_naive_bayes.predict(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccebdaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Score = 0.9524932488436137\n",
      "Best params = {'multinomialnb__alpha': 0.1, 'tfidfvectorizer__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of parameters\n",
    "parameters = {\n",
    "    'tfidfvectorizer__ngram_range': ((1,1), (2,2)),\n",
    "    'multinomialnb__alpha': (0.1,1),}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(pipeline_naive_bayes, parameters, scoring = \"recall\",\n",
    "                           cv = 5, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(data.text,data.spam)\n",
    "\n",
    "# Best score\n",
    "print(f\"Best Score = {grid_search.best_score_}\")\n",
    "\n",
    "# Best params\n",
    "print(f\"Best params = {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88f98703",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8cb1efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(sentence):\n",
    "    \n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() ## remove whitespaces\n",
    "    sentence = sentence.lower() ## lowercase \n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) ## remove numbers\n",
    "    \n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "    \n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenize \n",
    "    stop_words = set(stopwords.words('english')) ## define stopwords\n",
    "    \n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "        w for w in tokenized_sentence if not w in stop_words\n",
    "    ]\n",
    "\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\") \n",
    "        for word in tokenized_sentence_cleaned\n",
    "    ]\n",
    "    \n",
    "    cleaned_sentence = ' '.join(word for word in lemmatized)\n",
    "    \n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4a7a4711",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.DataFrame(['like mangos oranges', 'frog turtle live ponds', 'kitten puppies fluffy', 'spinach kiwi smoothie', 'kitten love strawberries'], columns = ['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "77eb2047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like mangos oranges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frog turtle live ponds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kitten puppies fluffy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spinach kiwi smoothie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kitten love strawberries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  documents\n",
       "0       like mangos oranges\n",
       "1    frog turtle live ponds\n",
       "2     kitten puppies fluffy\n",
       "3     spinach kiwi smoothie\n",
       "4  kitten love strawberries"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "203f5cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         like mangos oranges\n",
       "1      frog turtle live ponds\n",
       "2       kitten puppies fluffy\n",
       "3       spinach kiwi smoothie\n",
       "4    kitten love strawberries\n",
       "Name: documents, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_documents = documents[\"documents\"].apply(basic_cleaning)\n",
    "cleaned_documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7336f20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fluffy</th>\n",
       "      <th>frog</th>\n",
       "      <th>kitten</th>\n",
       "      <th>kiwi</th>\n",
       "      <th>like</th>\n",
       "      <th>live</th>\n",
       "      <th>love</th>\n",
       "      <th>mangos</th>\n",
       "      <th>oranges</th>\n",
       "      <th>ponds</th>\n",
       "      <th>puppies</th>\n",
       "      <th>smoothie</th>\n",
       "      <th>spinach</th>\n",
       "      <th>strawberries</th>\n",
       "      <th>turtle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.614189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495524</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614189</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495524</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614189</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.614189</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fluffy  frog    kitten     kiwi     like  live      love   mangos  \\\n",
       "0  0.000000   0.0  0.000000  0.00000  0.57735   0.0  0.000000  0.57735   \n",
       "1  0.000000   0.5  0.000000  0.00000  0.00000   0.5  0.000000  0.00000   \n",
       "2  0.614189   0.0  0.495524  0.00000  0.00000   0.0  0.000000  0.00000   \n",
       "3  0.000000   0.0  0.000000  0.57735  0.00000   0.0  0.000000  0.00000   \n",
       "4  0.000000   0.0  0.495524  0.00000  0.00000   0.0  0.614189  0.00000   \n",
       "\n",
       "   oranges  ponds   puppies  smoothie  spinach  strawberries  turtle  \n",
       "0  0.57735    0.0  0.000000   0.00000  0.00000      0.000000     0.0  \n",
       "1  0.00000    0.5  0.000000   0.00000  0.00000      0.000000     0.5  \n",
       "2  0.00000    0.0  0.614189   0.00000  0.00000      0.000000     0.0  \n",
       "3  0.00000    0.0  0.000000   0.57735  0.57735      0.000000     0.0  \n",
       "4  0.00000    0.0  0.000000   0.00000  0.00000      0.614189     0.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorized_documents = vectorizer.fit_transform(cleaned_documents)\n",
    "vectorized_documents = pd.DataFrame(vectorized_documents.toarray(), \n",
    "                                    columns = vectorizer.get_feature_names_out())\n",
    "\n",
    "vectorized_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21fe3aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(max_iter=100, n_components=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(max_iter=100, n_components=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(max_iter=100, n_components=2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Instantiate the LDA \n",
    "n_components = 2\n",
    "lda_model = LatentDirichletAllocation(n_components=n_components, max_iter = 100)\n",
    "\n",
    "# Fit the LDA on the vectorized documents\n",
    "lda_model.fit(vectorized_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "39f56534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.211863</td>\n",
       "      <td>0.788137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.197517</td>\n",
       "      <td>0.802483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.206331</td>\n",
       "      <td>0.793669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.808432</td>\n",
       "      <td>0.191568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.206333</td>\n",
       "      <td>0.793667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.211863  0.788137\n",
       "1  0.197517  0.802483\n",
       "2  0.206331  0.793669\n",
       "3  0.808432  0.191568\n",
       "4  0.206333  0.793667"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topic_mixture = lda_model.transform(vectorized_documents)\n",
    "pd.DataFrame(document_topic_mixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d10bc154",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topic_mixture = lda_model.transform(vectorized_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0bfe91a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19512686, 0.80487314],\n",
       "       [0.81417876, 0.18582124],\n",
       "       [0.20702716, 0.79297284],\n",
       "       [0.79882426, 0.20117574],\n",
       "       [0.76757279, 0.23242721]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topic_mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "961d9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(lda_model, vectorizer, top_words):\n",
    "    # 1. TOPIC MIXTURE OF WORDS FOR EACH TOPIC\n",
    "    topic_mixture = pd.DataFrame(\n",
    "        lda_model.components_,\n",
    "        columns = vectorizer.get_feature_names_out()\n",
    "    )\n",
    "    \n",
    "    # 2. FINDING THE TOP WORDS FOR EACH TOPIC\n",
    "    ## Number of topics\n",
    "    n_components = topic_mixture.shape[0]\n",
    "\n",
    "    ## Top words for each topic\n",
    "    for topic in range(n_components):\n",
    "        print(\"-\"*10)\n",
    "        print(f\"For topic {topic}, here are the the top {top_words} words with weights:\")\n",
    "\n",
    "        topic_df = topic_mixture.iloc[topic]\\\n",
    "            .sort_values(ascending = False).head(top_words)\n",
    "        \n",
    "        print(round(topic_df,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da8976ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(lda_model, vectorizer, top_words):\n",
    "    # 1. TOPIC MIXTURE OF WORDS FOR EACH TOPIC\n",
    "    topic_mixture = pd.DataFrame(lda_model.components_,\n",
    "                                 columns = vectorizer.get_feature_names_out())\n",
    "    \n",
    "    # 2. FINDING THE TOP WORDS FOR EACH TOPIC\n",
    "    ## Number of topics\n",
    "    n_components = topic_mixture.shape[0]\n",
    "    ## Top words for each topic\n",
    "    for topic in range(n_components):\n",
    "        print(\"-\"*10)\n",
    "        print(f\"For topic {topic}, here are the the top {top_words} words with weights:\")\n",
    "        topic_df = topic_mixture.iloc[topic]\\\n",
    "                             .sort_values(ascending = True).head(top_words)\n",
    "        \n",
    "        print(round(topic_df,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50c26500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "For topic 0, here are the the top 5 words with weights:\n",
      "frog      0.523\n",
      "live      0.523\n",
      "ponds     0.523\n",
      "turtle    0.523\n",
      "fluffy    0.524\n",
      "Name: 0, dtype: float64\n",
      "----------\n",
      "For topic 1, here are the the top 5 words with weights:\n",
      "kiwi        0.508\n",
      "smoothie    0.508\n",
      "spinach     0.508\n",
      "frog        0.977\n",
      "live        0.977\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print_topics(lda_model, vectorizer, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
